{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# loads the pre-processed variables\n",
    "%run load_helper.ipynb\n",
    "#\n",
    "\n",
    "# ##################################################\n",
    "#\n",
    "# QUICK START\n",
    "# For each run\n",
    "#       pick baseline\n",
    "#       name your run\n",
    "#       SET UP PARAMETERS\n",
    "#       then hit run\n",
    "#       if you wish to display the top words from significant topics see the word plot cell\n",
    "#       if you wish to visualize the topics for that run run the visualization cell\n",
    "# Repeat for a few runs\n",
    "#\n",
    "# Run the plotting cell\n",
    "#\n",
    "# NOTE: You may want to clean out files from the Run_data directory first\n",
    "#       It can get quite large \n",
    "#\n",
    "# NOTE: If you run the visualiztion cell, and then run another iteration\n",
    "#       you may get deprecation warnings (the visualization tool has not been updated)\n",
    "#       you can ignore those warnings - or reset the kernel from the kernel menu above before the run\n",
    "#\n",
    "# ##################################################\n",
    "\n",
    "\n",
    "# ##################################################\n",
    "#\n",
    "# pick a baseline\n",
    "#        baselines = [\"10topics2\", \"15topics2\", \"20topics2\", \"25topics2\", \"30topics2\"]\n",
    "#\n",
    "# NAME YOUR RUN (used to store the iterations); models will be saved myrun1.sav myrun2.save etc\n",
    "#\n",
    "# ##################################################\n",
    "\n",
    "# ##################################################\n",
    "#\n",
    "# set your global parameters\n",
    "#\n",
    "# NOTE if you want to run the algorithm from the paper\n",
    "#      set classical to 'y'\n",
    "#\n",
    "#      if you want to run the 'improved' algorithm\n",
    "#      set classical to 'n'\n",
    "#\n",
    "#      then set parameters in next section\n",
    "#\n",
    "# ##################################################\n",
    "mybaseline = \"30baseline2\"\n",
    "runname = \"Classic30T4I\"\n",
    "#runname = \"ClassicLowDecay\"\n",
    "\n",
    "classical = 'y'      # 'y' to run classical 'n' to run improved\n",
    "                     # if 'y' set parameters in the next section\n",
    "\n",
    "# ##################################################\n",
    "# classical = 'n' \n",
    "# \"Improved\"\n",
    "# ##################################################\n",
    "lda_decay = float(.001)      # how much the prior influences the iteration 0 - 1 \n",
    "                           #      mathmatically anything less than .5 is not guartenteed to converge\n",
    "                           #      however we have tuned the model to work down to .001 (and possibly lower)\n",
    "                           # if you do set this too low, Gensim will display warnings\n",
    "            \n",
    "num_iterations = 11  # NOTE this is in addition to baseline so if you want 14 results set this to 13 (0 is a counting word)\n",
    "                     # our tuning says to set this to about 13\n",
    "\n",
    "the_lag = 5 # lag of 5 is mentioned in the paper, and seems to work twith trial runs\n",
    "\n",
    "# ##################################################\n",
    "# classical = 'y' \n",
    "# ##################################################\n",
    "\n",
    "num_iterations_c = 4           # if you are going to use the algorthim in the paper (with splitting) set to around 4\n",
    "lda_decay_c = float(.5)        # how much the prior influences the iteration 0 - 1 \n",
    "the_lag_c = 5                  # lag of 5 is mentioned in the paper, and seems to work twith trial runs\n",
    "\n",
    "num_buffers = 0                   # how many buffers to add each iteration\n",
    "drop_percent = float(.95)         # as indicited in the paper, drop below .95 percent\n",
    "low_threshold = float(.05)        # threshold for the p-values .05 is pretty much expected\n",
    "ignore_little_counts = float(.2)  # if pos/neg words dominate, ignore the other topic\n",
    "\n",
    "\n",
    "\n",
    "# ##################################################\n",
    "#\n",
    "# The ITMFT algorithm\n",
    "#\n",
    "# ##################################################\n",
    "\n",
    "iteration = 0\n",
    "vis_name = \"\"\n",
    "itstoskip = 3\n",
    "#\n",
    "# load the baseline selected in the parameters above\n",
    "#\n",
    "if classical == 'y'  :\n",
    "    lda_decay =  lda_decay_c\n",
    "    num_iterations = num_iterations_c\n",
    "    the_lag = the_lag_c\n",
    "\n",
    "\n",
    "file_name = baseline_path + mybaseline + \".sav\"\n",
    "model = LdaModel.load(file_name)\n",
    "    \n",
    "topics = model.get_topics().copy()\n",
    "topics = topics.copy()\n",
    "num_topics = len(topics)\n",
    "print(\"Number of Topics = \", num_topics)\n",
    "\n",
    "run_purity = []\n",
    "run_confidence = []\n",
    "\n",
    "mostsigtopics = []\n",
    "mostsigtopicwords = []\n",
    "mostsigconf = float(2.0)\n",
    "\n",
    "#\n",
    "# loop through the iterations\n",
    "#\n",
    "while iteration < num_iterations  :\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"\\nIteration start time = \", current_time)\n",
    "    \n",
    "    # \n",
    "    # run either the \"classical\" or the \"improved\" algorithm\n",
    "    #\n",
    "    if classical == 'y'  :\n",
    "        %run itmtf_withsplit.ipynb \n",
    "    else :\n",
    "        %run itmtf_improved.ipynb \n",
    "    \n",
    "    #\n",
    "    # run the model\n",
    "    #\n",
    "    model = LdaModel(\n",
    "        corpus=corpus,\n",
    "        id2word=tokentoword,\n",
    "        chunksize=chunksize,\n",
    "        alpha='auto',               \n",
    "        eta=newtopics,                 # preset topic/word\n",
    "        iterations=iterations,\n",
    "        num_topics=num_topics,         # added buffer topics\n",
    "        passes=passes,\n",
    "        decay = lda_decay,\n",
    "        eval_every=eval_every\n",
    "    )\n",
    "\n",
    "    topics = model.get_topics().copy()\n",
    "    num_topics = len(topics)\n",
    " \n",
    "    file_name = runname + str(iteration) \n",
    "    path_name = save_path + file_name + \".sav\"\n",
    "    print(\"Model \" + file_name + \" - saved for visualization\")\n",
    "    model.save(path_name )\n",
    "    iteration += 1\n",
    "\n",
    "#\n",
    "# after the iterations are done\n",
    "# run the algorithm once more to gather stats from the last model\n",
    "#\n",
    "if classical == 'y'  :\n",
    "    %run itmtf_withsplit.ipynb \n",
    "else :\n",
    "    %run itmtf_improved.ipynb \n",
    "#\n",
    "file_name = runname + str(iteration) \n",
    "path_name = save_path + file_name + \".sav\"\n",
    "print(\"Model \" + file_name + \" - saved for visualization\")\n",
    "model.save(path_name )\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Run Complete = \", current_time)\n",
    " \n",
    "print (\"Significant Topics\", mostsigtopics)\n",
    "\n",
    "#\n",
    "# save the stats\n",
    "#\n",
    "path_name = save_path + runname + \".sigwords.csv\"\n",
    "fo = open(path_name, \"w\")\n",
    "firstime = 0\n",
    "for ii in range (0, len(mostsigtopics)) :\n",
    "    fo.write(str(mostsigtopics[ii]))\n",
    "    words = \" \"\n",
    "    for yy in range (0,10) :\n",
    "        if pearsoncorr[mostsigtopicwords[ii][yy][0]] > 0 :\n",
    "            words = words + \",B+: \" + tokentoword[mostsigtopicwords[ii][yy][0]]\n",
    "        else :\n",
    "            words = words + \",G+: \" + tokentoword[mostsigtopicwords[ii][yy][0]]\n",
    "    words = words + \"\\n\"\n",
    "    fo.write(words) \n",
    "fo.close()  \n",
    "\n",
    "path_name = save_path + runname + \".run.confidence.csv\"\n",
    "fo = open(path_name, \"w\")\n",
    "firstime = 0\n",
    "for num in run_confidence :\n",
    "    if firstime == 0 :\n",
    "        fo.write(str(num) )\n",
    "        firstime = 1\n",
    "    else :      \n",
    "        fo.write(\"\\n\" + str(num))                 \n",
    "fo.close()   \n",
    "\n",
    "if classical == 'y'  :\n",
    "    path_name = save_path + runname + \".run.purity.csv\"\n",
    "    fo = open(path_name, \"w\")\n",
    "    firstime = 0\n",
    "    for num in run_purity :\n",
    "        if firstime == 0 :\n",
    "            fo.write(str(num) )\n",
    "            firstime = 1\n",
    "        else :      \n",
    "            fo.write(\"\\n\" + str(num))                 \n",
    "    fo.close()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After each run\n",
    "# display the top 10 words for each significant topic\n",
    "\n",
    "# or display the words for any saved run\n",
    "#path_name = \".\\Run_data\\Improved30T14I.sigwords.csv\"\n",
    "path_name = save_path + runname + \".sigwords.csv\"\n",
    "%run run_words.ipynb\n",
    "draw_grid(path_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  \n",
    "\n",
    "# After a run\n",
    "# you can view the topics with this tool\n",
    "# it will display the model that the run has determined was the most significant\n",
    "#\n",
    "# Note: the numbering of the topics on this tool does not correspond to the topic number above\n",
    "#       this tool will show \"relevant\" terms - which mean frequency\n",
    "#       with the topic number in the tool representing topics in decending order of word frequency\n",
    "#\n",
    "#       But it is interesting to visualize\n",
    "#\n",
    "#       Top words are also stored in the Run_data directory \n",
    "#           with the name being RunName.sigwords.csv\n",
    "\n",
    "# NOTE\n",
    "# This library has not been updated for a while\n",
    "# it may give deprecation warnings\n",
    "# you can ignor those\n",
    "\n",
    "# you can select any model that was stored for visualization\n",
    "#vismodel = LdaModel.load(\".\\Run_data\\Improved14Iteration13.sav\")\n",
    "vismodel = LdaModel.load(vis_name)\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(vismodel, corpus, dictionary)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After you are finished with your runs\n",
    "# plot the run statistics\n",
    "#plotpath = \".\\\\Run_data\\\\\"\n",
    "\n",
    "#plotpath = \".\\\\Improved_baseline\\\\\"\n",
    "#plotpath = \".\\Classic_baseline\\\\\"\n",
    "plotpath = save_path\n",
    "%run run_plot.ipynb\n",
    "plot_run(plotpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Gensim",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
