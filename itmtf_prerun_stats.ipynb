{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# ##################################################\n",
    "#\n",
    "# Part of pre-processing\n",
    "# runs the pearson test on word streams and saves to file\n",
    "#\n",
    "# ##################################################\n",
    "\n",
    "\n",
    "# calculate Pearson's correlation\n",
    "print (len(bets))\n",
    "print(bets[0].dtype)\n",
    "trans = np.array(timeslicetokencounts).transpose()\n",
    "wordcorr = []\n",
    "print (len(trans[1]))\n",
    "print (len(timeslicetokencounts[1]))\n",
    "for yy in range(0,num_words) :\n",
    "    corr, _ = pearsonr(bets, trans[yy])\n",
    "    wordcorr.append(corr)\n",
    "    print('Pearsons correlation: %.3f' % corr)\n",
    "readfile = save_path + \"\\\\\" + \"pearson4.csv\"\n",
    "firstime = 0\n",
    "fo = open(readfile, \"w\") \n",
    "for num in wordcorr :\n",
    "    if firstime == 0 :\n",
    "        fo.write(str(num) )\n",
    "        firstime = 1\n",
    "    else :      \n",
    "        fo.write(\"\\n\" + str(num))\n",
    "fo.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# ##################################################\n",
    "#\n",
    "# Part of pre-processing\n",
    "# runs the granger test on word streams and saves to file\n",
    "#\n",
    "# ##################################################\n",
    "\n",
    "\n",
    "lowtopicsgc = []\n",
    "lowtopics = []\n",
    "trans = np.array(timeslicetokencounts).transpose()\n",
    "wordcorr = []\n",
    "print (len(trans[1]))\n",
    "print (len(timeslicetokencounts[1]))\n",
    "for yy in range(0,num_words) :\n",
    "    tempgc = grangercausalitytests([[bets[i],trans[yy][i]] for i in range(0, len(bets))], the_lag, verbose=False)\n",
    "    #tempgc = grangercausalitytests([[bets[i],topiccoverage[i][ii]] for i in range(0, len(bets))], the_lag, verbose=False)\n",
    "    #print(tempgc)\n",
    "    lowpvalue = 2\n",
    "    lowlag = 0\n",
    "    for yyy in range(1,the_lag+1) :\n",
    "        stats = tempgc.get(yyy)[0].get('ssr_ftest')\n",
    "        if (stats[1] < lowpvalue) :\n",
    "            lowlag = yyy\n",
    "            lowpvalue = stats[1]\n",
    "    stats = tempgc.get(lowlag)[0].get('ssr_ftest')\n",
    "    lowtopics.append(1-stats[1])\n",
    "print (\"Low Topics \", len(lowtopics))\n",
    "\n",
    "\n",
    "\n",
    "readfile = save_path + \"\\\\\" + \"grangerword.csv\"\n",
    "firstime = 0\n",
    "fo = open(readfile, \"w\") \n",
    "for num in lowtopics :\n",
    "    if firstime == 0 :\n",
    "        fo.write(str(num) )\n",
    "        firstime = 1\n",
    "    else :      \n",
    "        fo.write(\"\\n\" + str(num))\n",
    "fo.close() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################\n",
    "#\n",
    "# Part of pre-processing\n",
    "# adds the + or - from the parson test to the granger p-values\n",
    "#\n",
    "# ##################################################\n",
    "\n",
    "readfile = save_path + \"\\\\\" + \"grangerword.csv\"\n",
    "granger = [] \n",
    "fg = open(readfile, \"r\") \n",
    "for line in fg:\n",
    "    granger.append(float(line))\n",
    "fg.close()\n",
    "print(len(granger))\n",
    "                       \n",
    "pearson = []\n",
    "readfile = save_path + \"\\\\\" + \"pearson4.csv\"\n",
    "fp = open(readfile, \"r\") \n",
    "for line in fp:\n",
    "    pearson.append(float(line))\n",
    "fg.close()\n",
    "print(len(pearson))\n",
    "                       \n",
    "                       \n",
    "readfile = save_path + \"\\\\\" + \"pgranger.csv\"\n",
    "fo = open(readfile, \"w\") \n",
    "firstime = 0\n",
    "\n",
    "yy = 0\n",
    "while yy < len(granger) :\n",
    "    num = float(granger[yy])\n",
    "    if float(pearson[yy]) < 0 :\n",
    "        num = num * -1\n",
    "                       \n",
    "    if firstime == 0 :\n",
    "        fo.write(str(num) )\n",
    "        firstime = 1\n",
    "    else :      \n",
    "        fo.write(\"\\n\" + str(num))\n",
    "    yy += 1\n",
    "fo.close() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# ##################################################\n",
    "#\n",
    "# Just a little interesting pre-processing to see\n",
    "# which words are associated with what values\n",
    "# not used in algorithm\n",
    "#\n",
    "# ##################################################\n",
    "\n",
    "sigword = []\n",
    "\n",
    "readfile = save_path + \"\\\\\" + \"grangerword.csv\"\n",
    "fp = open(readfile, \"r\") \n",
    "for line in fp:\n",
    "    sigword.append(float(line))\n",
    "fp.close()\n",
    "\n",
    "\n",
    "readfile = save_path + \"\\\\\" + \"grangerwithword.csv\"\n",
    "fo = open(readfile, \"w\") \n",
    "ii = 0\n",
    "for num in sigword :\n",
    "    fo.write(tokentoword[ii] + \",\" + str(num) + \"\\n\" )\n",
    "    ii += 1\n",
    "fo.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Gensim",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
